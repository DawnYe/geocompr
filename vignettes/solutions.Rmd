---
title: "Geocomputation with R - Exercises and Solutions"
author: "Robin Lovelace, Jakub Nowosad, Jannes Muenchow"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

## Prerequisites {-}

The solutions assume the following packages are loaded (other packages will be loaded when needed):

```{r packages, message=FALSE, warning=FALSE}
library(sf)
library(tidyverse)
library(spData)
```

# Chapter 1

1. Think about the terms 'GIS', 'GDS' and 'Geocomputation' described above. Which is your favorite and and why?

1. Provide 3 reasons for using a scriptable language such R for geocomputation instead of established GIS programs such as QGIS.

- Reproducibility: a sequence of operations is much easier to save and share when using a scripting language.
- Scalability: scripting languages make it easy to break-up the work and parallelise, making it more scalable.
- Flexibility: the building blocks of the language allows it to interface efficiently with external software, enabling R to perform a wide range of tasks (e.g. animations, online interactive maps).
- Efficiency: the GUI of GIS programs can be slow to use and install.

1. Name two advantages and two disadvantages of using the older **sp** package compared with the new **sf** package.

- `+` Number of packages supported.
- `+` Stability
- `-` Slow performance
- `-` Non standard data format

# Chapter 2

1. What does the summary of the `geometry` column tell us about the `world` dataset, in terms of:

- The geometry type?
- How many countries there are?
- The coordinate reference system (CRS)?

2. Using **sf**'s `plot()` command, create a map of Nigeria in context, building on the code that creates and plots Asia above (see Figure \@ref(fig:nigeria) for an example of what this could look like). 

- Hint: this used the `lwd`, `main` and `col` arguments of `plot()`. 
- Bonus: make the country boundaries a dotted grey line.
- Hint: `border` is an additional argument of `plot()` for **sf** objects.

```{r nigeria, warning=FALSE, echo=FALSE, fig.cap="Map of Nigeria in context illustrating sf's plotting capabilities"}
nigeria = world[world$name_long == "Nigeria", ]
africa = world[world$continent == "Africa", ]
bb_africa = st_bbox(africa)
plot(africa[2], col = "white", lwd = 3, main = "Nigeria in context", border = "lightgrey")
# plot(world, lty = 3, add = TRUE, border = "grey")
plot(world, add = TRUE, border = "grey")
plot(nigeria, col = "yellow", add = TRUE, border = "darkgrey")
ncentre = st_centroid(nigeria)
ncentre_num = st_coordinates(ncentre)
text(x = ncentre_num[1], y = ncentre_num[2], labels = "Nigeria")
```

3. Exercise 3 <!--missing title-->

- What does the `lwd` argument do in the `plot()` code that generates Figure \@ref(fig:africa). 
- Perform the same operations and map making for another continent of your choice.
- Bonus: Download some global geographic data and add attribute variables assigning them to the continents of the world.

# Chapter 3

<!-- Attribute subsetting -->
1. Select only the `NAME` column in `us_states` and create a new object called `us_states_name`. 
What is the class of the new object? <!--why there is a "sf" part? -->
```{r}
us_states_name = us_states %>% dplyr::select(NAME)
class(us_states_name)
```
2. Select columns which contain information about a total population.
Think about as many ways as possible to do it. 
Hint: try to use helper functions, such as `contains` or `starts_with`.
```{r}
us_states %>% select(total_pop_10, total_pop_15)
```
```{r}
us_states %>% select(starts_with("total_pop"))
```
```{r}
us_states %>% select(contains("total_pop"))
```
3. Find all states that:
- Belongs to the Midwest region
```{r}
us_states %>% filter(total_pop_15 < 750000)
```
- Had a total population in 2015 lower than 750,000 residents
```{r}
us_states %>% filter(total_pop_15 < 750000)
```
- Belongs to the West region, had an area smaller than 250,000 km^2^ and total population in 2015 larger than 5,000,000 residents
```{r}
us_states %>% filter(REGION == "West", AREA < units::set_units(250000, km^2),total_pop_15 > 5000000)
# or
us_states %>% filter(REGION == "West", as.numeric(AREA) < 250000,total_pop_15 > 5000000)
```
- Belongs to the South region, had an area larger than 150,000 km^2^ or total population in 2015 larger than 7,000,000 residents
```{r}
us_states %>% filter(REGION == "South", AREA > units::set_units(150000, km^2), total_pop_15 > 7000000)
# or
us_states %>% filter(REGION == "South", as.numeric(AREA) > 150000, total_pop_15 > 7000000)
```
<!-- 4. Exercises about additional select and filter helper functions (one_of; between, is.na, near, etc.) -->
<!-- Attribute aggregation -->
4. What was the total population in 2015 in the `us_states` database? What was the minimum and maximum total population in 2015?
```{r}
us_states %>% summarize(total_pop = sum(total_pop_15),
                        min_pop = min(total_pop_15),
                        max_pop = max(total_pop_15))
```
5. How many states are in each region?
```{r}
us_states %>%
  group_by(REGION) %>%
  summarize(nr_of_states = n())
```
6. What was the minimum and maximum total population in 2015 in each region? What was the total population in 2015 in each region?
```{r}
us_states %>%
  group_by(REGION) %>%
  summarize(min_pop = min(total_pop_15),
            max_pop = max(total_pop_15),
            tot_pop = sum(total_pop_15))
```
<!-- Attribute joining -->
7. Add variables from `us_states_df` to `us_states` and create a new object called `us_states_stats`. What is the best function to do it? Which variable is the key in the both datasets? What is the class of a new object?
```{r}
us_states_stats = us_states %>%
  left_join(us_states_df, by = c("NAME" = "state"))
class(us_states_stats)
```
8. `us_states_df` has two more variables than `us_states`. How you can find them?
```{r}
us_states_df %>%
  anti_join(us_states, by = c("state" = "NAME"))
```
<!-- Attribute creation -->
9. What was the population density in 2015 in each state? What was the population density in 2010 in each state?
```{r}
us_states2 = us_states %>%
  mutate(pop_dens_15 = total_pop_15/AREA,
         pop_dens_10 = total_pop_10/AREA)
```
10. How much the population density changed between 2010 and 2015 in each state? Calculate the change in percentages.
```{r}
us_states2 %>%
  mutate(pop_dens_diff_10_15 = pop_dens_15 - pop_dens_10,
         pop_dens_diff_10_15p = (pop_dens_diff_10_15/pop_dens_15) * 100)
```
11. Change the columns names in `us_states` to lowercase. Try to use two helper functions - `tolower()` and `colnames()`.
```{r}
us_states %>%
  set_names(tolower(colnames(.)))
```
<!-- Mixed exercises -->
<!-- combination of use of select, mutate, group_by, summarize, etc  -->
12. Using `us_states` and `us_states_df` create a new object called `us_states_sel`. The new object should have only two variables - `median_income_15` and `geometry`. Change the name of the `median_income_15` column to `Income`.
```{r}
us_states %>%
  left_join(us_states_df, by = c("NAME" = "state")) %>%
  select(Income = median_income_15)
```
13. Calculate the change in median income between 2010 and 2015 for each state. What was the minimum, average and maximum median income in 2015 for each region? What is the region with the largest increase of the median income?
```{r}
us_states %>%
  left_join(us_states_df, by = c("NAME" = "state")) %>%
  mutate(income_change = median_income_15 - median_income_10) %>%
  group_by(REGION) %>%
  summarize(min_income_change = min(income_change),
            mean_income_change = mean(income_change),
            max_income_change = max(income_change)) %>%
  filter(mean_income_change == max(mean_income_change)) %>%
  pull(REGION) %>%
  as.character()
```

14. Create a raster from scratch with nine rows and columns and a resolution of 0.5 decimal degrees (WGS84).
Fill it with random numbers.
Extract the values of the four corner cells. 
```{r}
library(raster)
r = raster(nrow = 9, ncol = 9, res = 0.5, xmn = 0, xmx = 4.5,
           ymn = 0, ymx = 4.5, vals = rnorm(81))
# using cell IDs
r[c(1, 9, 81 - 9, 81)]
# using indexing
r[c(1, nrow(r)), c(1, ncol(r))]
# corresponds to [1, 1], [1, 9], [9, 1], [9, 9]
```
15. What is the most common class of our example raster `grain` (hint: `modal()`)?
```{r}
grain_size = c("clay", "silt", "sand")
grain = raster(nrow = 6, ncol = 6, res = 0.5, 
               xmn = -1.5, xmx = 1.5, ymn = -1.5, ymx = 1.5,
               vals = factor(sample(grain_size, 36, replace = TRUE), 
                             levels = grain_size))
cellStats(grain, modal) %>%
  factorValues(grain, .)
factorValues(grain, modal(values(grain)))
```
16. Plot the histogram and the boxplot of the `data(dem, package = "RQGIS")` raster. 
```{r}
data(dem, package = "RQGIS")
par(mfrow = c(1, 2))
hist(dem)
boxplot(dem)
```
17. Now attach also `data(ndvi, package = "RQGIS")`. 
Create a raster stack using `dem` and `ndvi`, and make a `pairs()` plot
```{r}
data(ndvi, package = "RQGIS")
s = stack(dem, ndvi)
pairs(s)
```

# Chapter 4

4. Use `data(dem, package = "RQGIS")`, and reclassify the elevation in three classes: low, middle and high.
Secondly, compute the NDVI (`data(ndvi, package = "RQGIS")`) and the mean elevation for each altitudinal class.
```{r}
library(classInt)
data(dem, package = "RQGIS")
summary(dem)
# find quantile breaks
brk = classIntervals(values(dem), n = 3)$brk
# also try
# breask = classIntervals(values(dem), n = 3, style = "fisher")
# construct reclassification matrix
rcl = matrix(c(brk[1] - 1, brk[2], 1, brk[2], brk[3], 2, brk[3], brk[4], 3), 
             ncol = 3, byrow = TRUE)
# reclassify altitudinal raster
recl = reclassify(dem, rcl = rcl)
# compute the mean dem and ndvi values for each class
zonal(stack(dem, ndvi), recl, fun = "mean")
```

5. Apply a line detection filter to `data(dem, package = "RQGIS")`.
```{r}
# from the focal help page:
# Laplacian filter: filter=matrix(c(0,1,0,1,-4,1,0,1,0), nrow=3)
# Sobel filter: filter=matrix(c(1,2,1,0,0,0,-1,-2,-1) / 4, nrow=3)
# compute the Sobel filter
# check if there are NAs
is.na(dem)  # just 0s, so no NAs
sobel = focal(dem, w = matrix(c(1, 2, 1, 0, 0, 0, -1, -2, -1) / 4, nrow = 3))
# CHECK IF THIS IS CORRECT
```

6. Calculate the NDVI of a Landsat image. 
Use the Landsat image provided by the **spDataLarge** package (`system.file("raster/landsat.tif", package="spDataLarge")`).
```{r}
file = system.file("raster/landsat.tif", package="spDataLarge")
r = stack(file)
# compute NDVI manually
ndvi = (r[["landsat.4"]] - r[["landsat.3"]]) / (r[["landsat.4"]] + r[["landsat.3"]])
# compute NDVI with the help of RStoolbox
library(RStoolbox)
ndvi_rstoolbox = spectralIndices(r, red = 3, nir = 4, indices = "NDVI")
all.equal(ndvi, ndvi_rstoolbox)
```

7. This [post](https://stackoverflow.com/questions/35555709/global-raster-of-geographic-distances) shows how to use `raster::distance()`.
Extract Spain, calculate a distance raster and weight it with elevation.
Finally, compute the difference between the raster using the euclidean distance and the raster weighted by elevation.
(Hint: Have a look at `getData()` to retrieve a digital elevation model for Spain.)
```{r}
library(raster)
# find out the ISO_3 code of Spain
dplyr::filter(ccodes(), NAME %in% "Spain")
# retrieve a dem of Spain
dem = getData("alt", country = "ESP", mask = FALSE)
# change the resolution to decrease computing time
agg = aggregate(dem, fact = 5)
poly = getData("GADM", country = "ESP", level = 1)
plot(dem)
plot(poly, add = TRUE)
# visualize NAs
plot(is.na(agg))
# construct a distance input raster
# we have to set the land cells to NA and the sea cells to an arbitrary value since 
# raster::distance computes the distance to the nearest non-NA cell
dist = is.na(agg)
cellStats(dist, summary)
# convert land cells into NAs and sea cells into 1s
dist[dist == FALSE] = NA
dist[dist == TRUE] = 1
plot(dist)
# compute distance to nearest non-NA cell
dist = raster::distance(dist)
# just keep Spain
dist = mask(dist, poly)
# convert distance into km
dist = dist / 1000
# now let's weight each 100 altitudinal meters by an additionaly distance of 10 km
agg = mask(agg, poly)
agg[agg < 0] = 0
weight = dist + agg / 100 * 10
plot(weight - dist)
```

# Chapter 5

# Chapter R-GIS bridges

1. Create two overlapping polygons (`poly_1` and `poly_2`) with the help of the **sf**-package (see chapter \@ref(spatial-class)). 
Calculate the intersection using:

- **RQGIS**, **RSAGA** and **rgrass7**
- **sf**

```{r, eval=FALSE}
library(sf)
library(RQGIS)
# create two polygons
coords_1 =  
  matrix(data = c(0, 0, 1, 0, 1, 1, 0, 1, 0, 0),
         ncol = 2, byrow = TRUE)
coords_2 =
  matrix(data = c(-0.5, -0.5, 0.5, -0.5, 0.5, 0.5, 
                  -0.5, 0.5, -0.5, -0.5),
         ncol = 2, byrow = TRUE)

# create the first polygon
poly_1 = st_polygon(list((coords_1))) 
# convert it into a simple feature collection 
poly_1 = st_sfc(poly_1)
poly_1 = st_sfc(poly_1, crs = 4326)
# finally, convert it into an sf-object
poly_1 = st_sf(geometry = poly_1, data = data.frame(id = 1))

# create a second polygon
poly_2 = st_polygon(list((coords_2))) %>%
  st_sfc(., crs = 4326) %>%
  st_sf(geometry = ., data = data.frame(id = 1))
# visualize it
plot(st_geometry(poly_1), xlim = c(-1, 1), ylim = c(-1, 1))
plot(st_geometry(poly_2), add = TRUE)

# INTERSECTION USING RQGIS
#***************************
# first of all, we need to find out which function might do this for us
find_algorithms("intersec")
open_help("qgis:intersection")
get_usage("qgis:intersection")
# using R named arguments#
int_qgis = run_qgis("qgis:intersection", INPUT = poly_1, INPUT2 = poly_2,
                    OUTPUT = "int_qgis.shp", load_output = TRUE)
# visualize it
plot(st_geometry(poly_1), xlim = c(-1, 1), ylim = c(-1, 1))
plot(st_geometry(poly_2), add = TRUE)
plot(int_qgis, col = "lightblue", add = TRUE)


# INTERSECTION USING RSAGA
#***************************
# The RSAGA examples only work with SAGA < 2.3. We have informed the
# package maintainer to update SAGA
library(RSAGA)
library(link2GI)
linkSAGA()
rsaga.env()
# save shapefile layers
write_sf(poly_1, file.path(tempdir(), "poly_1.shp"))
write_sf(poly_2, file.path(tempdir(), "poly_2.shp"))
# find out how to union shapefiles with the help of SAGA
rsaga.get.modules(lib = "shapes_polygons")
rsaga.get.usage(lib = "shapes_polygons", module = "Intersect")
# create parameter-argument list for RSAGA
params = list(A = file.path(tempdir(), "poly_1.shp"),
              B = file.path(tempdir(), "poly_2.shp"),
              RESULT = file.path(tempdir(), "int_saga.shp"))
rsaga.geoprocessor(lib = "shapes_polygons", module = "Intersect", 
                   param = params)
int_saga = st_read(file.path(tempdir(), "int_saga.shp"))
# visualize it
plot(st_geometry(poly_1), xlim = c(-1, 1), ylim = c(-1, 1))
plot(st_geometry(poly_2), add = TRUE)
plot(st_geometry(int_saga), col = "lightblue", add = TRUE)

# INTERSECTION USING rgrass7
#***************************
library(link2GI)
library(rgrass7)
link2GI::linkGRASS7(rbind(poly_1, poly_2), ver_select = TRUE)
# let's have a look at the help of v.overlay via rgrass7
execGRASS("g.manual", entry = "v.overlay")
# RQGIS::open_help("grass7:v.overlay")
writeVECT(as(poly_1, "Spatial"), vname = "poly_1")
writeVECT(as(poly_2, "Spatial"), vname = "poly_2")
execGRASS("v.overlay", ainput = "poly_1", binput = "poly_2",
          output = "int_grass", operator = "and", flag = "overwrite")
out_grass <- readVECT("int_grass")
plot(st_geometry(poly_1), xlim = c(-1, 1), ylim = c(-1, 1))
plot(st_geometry(poly_2), add = TRUE)
plot(int_grass, add = TRUE, col = "lightblue")

# INTERSECTION USING sf
#***************************

int_sf = st_intersection(poly_1, poly_2)
plot(st_geometry(poly_1), xlim = c(-1, 1), ylim = c(-1, 1))
plot(st_geometry(poly_2), add = TRUE)
plot(int_sf, add = TRUE, col = "lightblue")
```

2. Run `data(dem, package = "RQGIS")` and `data(random_points, package = "RQGIS")`.
Select randomly a point from `random_points` and find all `dem` pixels that can be seen from this point (hint: viewshed).
Visualize your result.
For example, plot a hillshade, and on top of it the digital elevation model, your viewshed output and the point.
Additionally, give `mapview` a try.

```{r, eval=FALSE}
library(RQGIS)
library(raster)
data(dem, package = "RQGIS")
data(random_points, package = "RQGIS")

find_algorithms("viewshed")
alg = "grass7:r.viewshed"
get_usage(alg)
open_help(alg)
# let's find out about the default values
get_args_man(alg)
point = random_points[sample(1:nrow(random_points), 1), ]
coord = paste(sf::st_coordinates(point), collapse = ",")
out = run_qgis(alg, input = dem, coordinates = coord,
               output = "out.tif", load_output = TRUE)

# under Linux this might not work, in this case use rgrass7 directly
library(rgrass7)
link2GI::linkGRASS7(dem, ver_select = TRUE)
writeRAST(as(dem, "SpatialGridDataFrame"), "dem")
writeVECT(as(random_points, "Spatial"), vname = "points")
execGRASS("r.viewshed", input = "dem", coordinates = sf::st_coordinates(point),
          output = "view")
out = raster(readRAST("view"))

hs = hillShade(terrain(dem), terrain(dem, "aspect"), 40, 270)
plot(hs, col = gray(0:100 / 100), legend = FALSE)
plot(dem, add = TRUE, alpha = 0.5, legend = FALSE)
plot(point, add = TRUE, col = "red", pch = 16)
plot(out, add = TRUE, col = "lightgray", legend = FALSE)
plot(point, add = TRUE, col = "red", pch = 16)

# or using mapview
library(mapview)
mapview(out, col = "white", map.type = "Esri.WorldImagery") +
  mapview(point)
```
